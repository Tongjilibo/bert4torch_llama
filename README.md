# bert4torch_llama
基于bert4torch的llama预测

1. 下载链接：[源项目](https://github.com/facebookresearch/llama) | [huggingface第三方](https://huggingface.co/decapoda-research/llama-7b-hf) | [种子下载](https://pan.baidu.com/s/1yBaYZK5LHIbJyCCbtFLW3A?pwd=phhd)，本人实现是基于第三种
2. 权重转换：[转换链接](https://github.com/Tongjilibo/bert4torch/blob/master/examples/convert_script/convert_llama_facebook.py)
3. 预测脚本：[预测链接](https://github.com/Tongjilibo/bert4torch/blob/master/examples/basic/basic_language_model_llama.py)
4. 资源占用：fp32单卡占用约27G, fp16单卡占用约14g
